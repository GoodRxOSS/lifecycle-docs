[
  {
    "title": "Introducing Lifecycle",
    "description": null,
    "date": "2025-05-23",
    "path": "articles/introduction",
    "body": "We started building **Lifecycle** at GoodRx in 2019 because managing our lower environments like staging, development, QA had become a daily headache. As our architecture shifted from a monolith to microservices, our internal channels were flooded with messages like \"Is anyone using staging?\" \"Staging is broken again,\" and \"Who just overwrote my changes?\" Waiting in line for hours (sometimes days) to test code in a real-world-like environment was the norm.\n\nWe simply couldn't scale with our engineering growth. So, as a proof of concept, we spun up **Lifecycle**: a tool that lets you create on-demand, ephemeral environments off of github pull request.\n\nAt first, only a handful of services were onboarded, but our engineers immediately saw the difference, no more static staging servers, no more pipeline gymnastics, and no more accidental overwrites. They wanted Lifecycle wherever they touched code, so we built a simple lifecycle.yaml configuration, replaced our manual database entries, and baked Lifecycle support into every new service template.\n\nAfter ironing out early scaling kinks, we realized Lifecycle had become more than an internal convenience, it was a game-changer for us.\n\nToday (June 5, 2025), we're thrilled to open-source five years of collective effort under the Apache 2.0 license. This project represents countless late-night brainstorming sessions, pull requests, and \"aha\" moments, and we can't wait to see how you'll make it your own: adding integrations, optimizing performance, or finding novel workflows we never imagined.\n\nBy sharing Lifecycle, we hope to help teams stuck in the same limited environment limbo we once were and build a community of passionate likeminded developers who'll shape the the future of Lifecycle.\n\nWe look forward to learning from you, growing together, and making shipping high-quality software faster and more enjoyable for everyone!\n\nJoin our Discord server [here](https://discord.gg/TEtKgCs8T8) to connect!!"
  },
  {
    "title": "What is Lifecycle?",
    "description": "Lifecycle is your effortless way to test and create ephemeral environments",
    "date": "2025-03-12",
    "path": "docs/what-is-lifecycle",
    "body": "Lifecycle is an **ephemeral** _(/…ôÀàfem(…ô)r…ôl/, lasting for a very short time)_ environment orchestrator that transforms your GitHub pull requests into fully functional development environments. It enables developers to test, validate, and collaborate on features without the hassle of managing infrastructure manually.\n\n> With **Lifecycle**, every pull request gets its own connected playground‚Äîensuring that changes can be previewed, integrated, and verified before merging into its main branch.\n\n## A Developer‚Äôs Story\n\nImagine working in an organization that develops multiple services. Managing and testing changes across these services can be challenging, especially when multiple developers are working on different features simultaneously.\n\nMeet **Nick Holiday üë®‚Äçüíª**, an engineer who needs to update a database schema and modify the corresponding API in a backend service. Additionally, his change requires frontend service updates to display the new data correctly.\n\n### Traditional Workflow Challenges\n\n- **Shared environments** ‚Äì Nick deploys his backend service changes to a shared dev or staging environment, but another engineer is testing unrelated changes at the same time.\n- **Conflicting updates** ‚Äì The frontend engineers working on the UI might face issues if their code depends on a stable backend service that keeps changing.\n- **Environment management** ‚Äì Setting up and maintaining an isolated environment for testing requires significant effort.\n\n### Enter Lifecycle\n\nWith Lifecycle, as soon as Nick opens a pull request, the system automatically:\n\n1. üèóÔ∏è **Creates an isolated development environment** ‚Äì This environment includes Nick‚Äôs updated backend service along with the necessary frontend services.\n2. üöÄ **Deploys the application** ‚Äì Everything is set up exactly as it would be in production, ensuring a reliable test scenario.\n3. üîó **Generates a shareable URL** ‚Äì Nick and his teammates can interact with the new features without setting up anything locally.\n4. üßπ **Cleans up automatically** ‚Äì Once the PR is merged or closed, Lifecycle removes the environment, keeping things tidy.\n\n## Watch a Quick Demo\n\n\n\n## How It Works\n\n\n\n## Why Use Lifecycle?\n\n- **Faster Feedback Loops** - Get instant previews of your changes without waiting for staging deployments.\n- **Isolation** - Each PR runs in its own sandbox, preventing conflicts.\n- **Seamless Collaboration** - Share URLs with stakeholders, designers, or QA engineers.\n- **Automatic Cleanup** - No more stale test environments; Lifecycle manages cleanup for you.\n- **Works with Your Stack** - Supports containerized applications and integrates with Kubernetes."
  },
  {
    "title": "Auto Deploy & Labels",
    "description": "How to setup auto deploy for pull requests and control envionment with labels",
    "date": "2025-01-29",
    "path": "docs/features/auto-deployment",
    "body": "## Auto-Deploy Configuration\n\nTo enable **automatic deployment** when a PR is created, set the `autoDeploy` attribute in your repository's `lifecycle.yaml` file:\n\n```yaml {2} filename=\"lifecycle.yaml\"\nenvironment:\n  autoDeploy: true\n  defaultServices:\n```\n\n- Lifecycle will **automatically create** the environment as soon as a PR is opened.\n- A `lifecycle-deploy!` label will be added to the PR to indicate that the environment has been deployed.\n\n---\n\n## Managing Deployments with Labels\n\nIf **auto-deploy is not enabled**, you can manually control the environment using PR labels.\n\n### Deploy an Environment\n\nTo create an ephemeral environment for a PR, **add** the `lifecycle-deploy!` label.\n\n### Tear Down an Environment\n\nTo **delete** an active environment, use either of these labels:\n\n- **Remove** `lifecycle-deploy!`\n- **Add** `lifecycle-disabled!`\n\n---\n\n## Automatic Cleanup on PR Closure\n\nWhen a PR is **closed**, Lifecycle will:\n\n1. **Tear down** the active environment.\n2. **Remove** the `lifecycle-deploy!` label from the PR.\n\nThis ensures that unused environments do not persist after the PR lifecycle is complete.\n\n---\n\n## Summary\n\n| Feature                      | Behavior                                        |\n| ---------------------------- | ----------------------------------------------- |\n| `autoDeploy: true` in config | PR environments are **automatically** deployed. |\n| `lifecycle-deploy!`          | **Manually deploy** an environment.             |\n| Remove `lifecycle-deploy!`   | **Tear down** the environment.                  |\n| Add `lifecycle-disabled!`    | **Tear down** the environment manually.         |\n| PR closed                    | **Environment is deleted automatically**.       |\n\nUsing these configurations and labels, teams can efficiently manage **ephemeral environments** in their development workflow."
  },
  {
    "title": "Webhooks",
    "description": null,
    "date": "2025-02-16",
    "path": "docs/features/webhooks",
    "body": "Lifecycle can invoke **third-party services** when a build state changes. Currently, only **Codefresh pipeline triggers** are supported. Webhooks allow users to automate external processes such as running tests or performing cleanup tasks based on environment build states.\n\n## Common Use Cases\n\n- When a build status is `deployed`, trigger **end-to-end tests**.\n- When a build status is `error`, trigger **infrastructure cleanup** or alert the team.\n\n## Webhook Configuration\n\nWebhooks are defined in the `lifecycle.yaml` under the `environment.webhooks` section.\n\nBelow is an example configuration for triggering end-to-end tests when the `deployed` state is reached.\n\n### **Examples**\n\n```yaml\n# Trigger End-to-End Tests on Deployment\nenvironment:\n  # ...\n  defaultServices:\n    - name: \"frontend\"\n  optionalServices:\n    - name: \"backend\"\n      repository: \"lifecycle/backend\"\n      branch: \"main\"\n  webhooks:\n    - state: deployed\n      type: codefresh\n      name: \"End to End Tests\"\n      pipelineId: 64598362453cc650c0c9cd4d\n      trigger: tests\n      env:\n        branch: \"{{frontend_branchName}}\"\n        TEST_URL: \"https://{{frontend_publicUrl}}\"\n  # ...\n```\n\n- **`state: deployed`** ‚Üí Triggers the webhook when the build reaches the `deployed` state.\n- **`type: codefresh`** ‚Üí Specifies that this webhook triggers a **Codefresh pipeline**.\n- **`name`** ‚Üí A human-readable name for the webhook.\n- **`pipelineId`** ‚Üí The unique Codefresh pipeline ID.\n- **`trigger`** ‚Üí Codefresh pipeline's trigger to execute.\n- **`env`** ‚Üí Passes relevant environment variables (e.g., `branch` and `TEST_URL`).\n\n---\n\n```yaml\n# Trigger Cleanup on Build Error\nenvironment:\n  # ...\n  webhooks:\n    - state: error\n      type: codefresh\n      name: \"Cleanup Failed Deployment\"\n      pipelineId: 74283905723ff650c0d9ab7e\n      trigger: cleanup\n      env:\n        branch: \"{{frontend_branchName}}\"\n        CLEANUP_TARGET: \"frontend\"\n  # ...\n```\n\n- **`state: error`** ‚Üí Triggers the webhook when the build fails.\n- **`type: codefresh`** ‚Üí Invokes a Codefresh cleanup pipeline.\n- **`trigger: cleanup`** ‚Üí Codefresh pipeline's trigger to execute.\n- **`env`** ‚Üí Includes necessary variables, such as `branch` and `CLEANUP_TARGET`.\n\n## Limitations\n\n- **Currently, Lifecycle only supports Codefresh pipeline triggers.**\n- In need of support for other webhook types? please **submit a pull request or an issue**.\n\nBy leveraging webhooks, teams can **automate workflows, run tests, and clean up failed deployments** seamlessly within Lifecycle."
  },
  {
    "title": "Native Helm Deployment",
    "description": "Deploy services using Helm directly in Kubernetes without external CI/CD dependencies",
    "date": "2025-01-29",
    "path": "docs/features/native-helm-deployment",
    "body": "This feature is still in alpha and might change with breaking changes.\n\n\n**Native Helm** is an alternative deployment method that runs Helm deployments directly within Kubernetes jobs, eliminating the need for external CI/CD systems. This provides a more self-contained and portable deployment solution.\n\n\n  Native Helm deployment is an opt-in feature that can be enabled globally or\n  per-service.\n\n\n## Overview\n\nWhen enabled, Native Helm:\n\n- Creates Kubernetes jobs to execute Helm deployments\n- Runs in ephemeral namespaces with proper RBAC\n- Provides real-time deployment logs via WebSocket\n- Handles concurrent deployments automatically\n- Supports all standard Helm chart types\n\n## Quickstart\n\nWant to try native Helm deployment? Here's the fastest way to get started:\n\n```yaml filename=\"lifecycle.yaml\" {5}\nservices:\n  - name: my-api\n    defaultUUID: \"dev-0\"\n    helm:\n      deploymentMethod: \"native\" # That's it!\n      chart:\n        name: \"local\"\n        valueFiles:\n          - \"./helm/values.yaml\"\n```\n\nThis configuration:\n\n1. Enables native Helm for the `my-api` service\n2. Uses a local Helm chart from your repository\n3. Applies values from `./helm/values.yaml`\n4. Runs deployment as a Kubernetes job\n\n\n  To enable native Helm for all services at once, see [Global\n  Configuration](#enabling-native-helm).\n\n\n## Configuration\n\n### Enabling Native Helm\n\nThere are two ways to enable native Helm deployment:\n\n#### Per Service Configuration\n\nEnable native Helm for individual services:\n\n```yaml {4} filename=\"lifecycle.yaml\"\nservices:\n  - name: my-service\n    helm:\n      deploymentMethod: \"native\" # Enable for this service only\n      chart:\n        name: my-chart\n```\n\n#### Global Configuration\n\nEnable native Helm for all services:\n\n```yaml {3} filename=\"lifecycle.yaml\"\nhelm:\n  nativeHelm:\n    enabled: true # Enable for all services\n```\n\n### Configuration Precedence\n\nLifecycle uses a hierarchical configuration system with three levels of precedence:\n\n1. **helmDefaults** - Base defaults for all deployments (database: `global_config` table)\n2. **Chart-specific config** - Per-chart defaults (database: `global_config` table)\n3. **Service YAML config** - Service-specific overrides (highest priority)\n\n\n  Service-level configuration always takes precedence over global defaults.\n\n\n### Global Configuration (Database)\n\nGlobal configurations are stored in the `global_config` table in the database. Each configuration is stored as a row with:\n\n- **key**: The configuration name (e.g., 'helmDefaults', 'postgresql', 'redis')\n- **config**: JSON object containing the configuration\n\n#### helmDefaults Configuration\n\nStored in database with key `helmDefaults`:\n\n```json\n{\n  \"nativeHelm\": {\n    \"enabled\": true,\n    \"defaultArgs\": \"--wait --timeout 30m\",\n    \"defaultHelmVersion\": \"3.12.0\"\n  }\n}\n```\n\n**Field Descriptions**:\n\n- `enabled`: When `true`, enables native Helm deployment for all services unless they explicitly set `deploymentMethod: \"ci\"`\n- `defaultArgs`: Arguments automatically appended to every Helm command (appears before service-specific args)\n- `defaultHelmVersion`: The Helm version to use when not specified at the service or chart level\n\n#### Chart-specific Configuration\n\nExample: PostgreSQL configuration stored with key `postgresql`:\n\n```json\n{\n  \"version\": \"3.13.0\",\n  \"args\": \"--force --timeout 60m0s --wait\",\n  \"chart\": {\n    \"name\": \"postgresql\",\n    \"repoUrl\": \"https://charts.bitnami.com/bitnami\",\n    \"version\": \"12.9.0\",\n    \"values\": [\"auth.username=postgres_user\", \"auth.database=postgres_db\"]\n  }\n}\n```\n\n\n  These global configurations are managed by administrators and stored in the\n  database. They provide consistent defaults across all environments and can be\n  overridden at the service level.\n\n\n## Usage Examples\n\n### Quick Experiment: Deploy Jenkins!\n\nWant to see native Helm in action? Let's deploy everyone's favorite CI/CD tool - Jenkins! This example shows how easy it is to deploy popular applications using native Helm.\n\n```yaml filename=\"lifecycle.yaml\"\nenvironment:\n  defaultServices:\n    - name: \"my-app\"\n    - name: \"jenkins\" # Add Jenkins to your default services\n\nservices:\n  - name: \"jenkins\"\n    helm:\n      deploymentMethod: \"native\"\n      repository: \"myorg/apps\"\n      branchName: \"main\"\n      chart:\n        name: \"jenkins\"\n        repoUrl: \"https://charts.bitnami.com/bitnami\"\n        version: \"13.6.8\"\n        values:\n          - \"service.type=ClusterIP\"\n          - \"ingress.enabled=true\"\n          - \"ingress.hostname={{jenkins_publicUrl}}\"\n          - \"ingress.ingressClassName=nginx\"\n```\n\n\n  üéâ That's it! With just a few lines of configuration, you'll have Jenkins\n  running in your Kubernetes cluster.\n\n\nTo access your Jenkins instance:\n\n1. Check the deployment status in your PR comment\n2. Click the **Deploy Logs** link to monitor the deployment\n3. Once deployed, Jenkins will be available at the internal hostname\n\n\n  For more Jenkins configuration options and values, check out the [Bitnami\n  Jenkins chart\n  documentation](https://github.com/bitnami/charts/tree/main/bitnami/jenkins).\n  This same pattern works for any Bitnami chart (PostgreSQL, Redis, MongoDB) or\n  any other public Helm chart!\n\n\n### Basic Service Deployment\n\n```yaml filename=\"lifecycle.yaml\"\nservices:\n  - name: web-api\n    helm:\n      deploymentMethod: \"native\"\n      chart:\n        name: web-app\n        version: \"1.2.0\"\n```\n\n### PostgreSQL with Overrides\n\n```yaml filename=\"lifecycle.yaml\"\nservices:\n  - name: database\n    helm:\n      deploymentMethod: \"native\"\n      version: \"3.14.0\" # Override Helm version\n      args: \"--atomic\" # Override deployment args\n      chart:\n        name: postgresql\n        values: # Additional values merged with defaults\n          - \"persistence.size=20Gi\"\n          - \"replicaCount=2\"\n```\n\n### Custom Environment Variables\n\nLifecycle supports flexible environment variable formatting through the `envMapping` configuration. This feature allows you to control how environment variables from your service configuration are passed to your Helm chart.\n\n\n  **Why envMapping?** Different Helm charts expect environment variables in\n  different formats. Some expect an array of objects with `name` and `value`\n  fields (Kubernetes standard), while others expect a simple key-value map. The\n  `envMapping` feature lets you adapt to your chart's requirements.\n\n\n#### Default envMapping Configuration\n\nYou can define default `envMapping` configurations in the `global_config` database table. These defaults apply to all services using that chart unless overridden at the service level.\n\n**Example: Setting defaults for your organization's chart**\n\n```json\n// In global_config table, key: \"myorg-web-app\"\n{\n  \"chart\": {\n    \"name\": \"myorg-web-app\",\n    \"repoUrl\": \"https://charts.myorg.com\"\n  },\n  \"envMapping\": {\n    \"app\": {\n      \"format\": \"array\",\n      \"path\": \"deployment.containers[0].env\"\n    }\n  }\n}\n```\n\nWith this configuration, any service using the `myorg-web-app` chart will automatically use array format for environment variables:\n\n```yaml filename=\"lifecycle.yaml\"\nservices:\n  - name: api\n    helm:\n      deploymentMethod: \"native\"\n      chart:\n        name: \"myorg-web-app\" # Inherits envMapping from global_config\n      docker:\n        app:\n          env:\n            API_KEY: \"secret\"\n            # These will be formatted as array automatically\n```\n\n\n  Setting `envMapping` in global_config is particularly useful when: - You have\n  a standard organizational chart used by many services - You want consistent\n  environment variable handling across services - You're migrating multiple\n  services and want to reduce configuration duplication\n\n\n#### Array Format\n\nBest for charts that expect Kubernetes-style env arrays.\n\n```yaml {7-9} filename=\"lifecycle.yaml\"\nservices:\n  - name: api\n    helm:\n      deploymentMethod: \"native\"\n      chart:\n        name: local\n      envMapping:\n        app:\n          format: \"array\"\n          path: \"env\"\n      docker:\n        app:\n          env:\n            DATABASE_URL: \"postgres://localhost:5432/mydb\"\n            API_KEY: \"secret-key-123\"\n            NODE_ENV: \"production\"\n```\n\n**This produces the following Helm values:**\n\n```bash\n--set env[0].name=DATABASE_URL\n--set env[0].value=postgres://localhost:5432/mydb\n--set env[1].name=API_KEY\n--set env[1].value=secret-key-123\n--set env[2].name=NODE_ENV\n--set env[2].value=production\n```\n\n**Your chart's values.yaml would use it like:**\n\n```yaml\nenv:\n  - name: DATABASE_URL\n    value: postgres://localhost:5432/mydb\n  - name: API_KEY\n    value: secret-key-123\n  - name: NODE_ENV\n    value: production\n```\n\n#### Map Format\n\nBest for charts that expect a simple key-value object.\n\n```yaml {7-9} filename=\"lifecycle.yaml\"\nservices:\n  - name: api\n    helm:\n      deploymentMethod: \"native\"\n      chart:\n        name: local\n      envMapping:\n        app:\n          format: \"map\"\n          path: \"envVars\"\n      docker:\n        app:\n          env:\n            DATABASE_URL: \"postgres://localhost:5432/mydb\"\n            API_KEY: \"secret-key-123\"\n            NODE_ENV: \"production\"\n```\n\n**This produces the following Helm values:**\n\n```bash\n--set envVars.DATABASE__URL=postgres://localhost:5432/mydb\n--set envVars.API__KEY=secret-key-123\n--set envVars.NODE__ENV=production\n```\n\n\n  Note: Underscores in environment variable names are converted to double\n  underscores (`__`) in map format to avoid Helm parsing issues.\n\n\n**Your chart's values.yaml would use it like:**\n\n```yaml\nenvVars:\n  DATABASE__URL: postgres://localhost:5432/mydb\n  API__KEY: secret-key-123\n  NODE__ENV: production\n```\n\n#### Complete Example with Multiple Services\n\n```yaml filename=\"lifecycle.yaml\"\nservices:\n  # Service using array format (common for standard Kubernetes deployments)\n  - name: frontend\n    helm:\n      deploymentMethod: \"native\"\n      repository: \"myorg/apps\"\n      branchName: \"main\"\n      envMapping:\n        app:\n          format: \"array\"\n          path: \"deployment.env\"\n      chart:\n        name: \"./charts/web-app\"\n      docker:\n        app:\n          dockerfilePath: \"frontend/Dockerfile\"\n          env:\n            REACT_APP_API_URL: \"https://api.example.com\"\n            REACT_APP_VERSION: \"{{build.uuid}}\"\n\n  # Service using map format (common for custom charts)\n  - name: backend\n    helm:\n      deploymentMethod: \"native\"\n      repository: \"myorg/apps\"\n      branchName: \"main\"\n      envMapping:\n        app:\n          format: \"map\"\n          path: \"config.environment\"\n      chart:\n        name: \"./charts/api\"\n      docker:\n        builder:\n          engine: \"buildkit\"\n        defaultTag: \"main\"\n        app:\n          dockerfilePath: \"docker/backend.dockerfile\"\n          ports:\n            - 3000\n          env:\n            NODE_ENV: \"production\"\n            SERVICE_NAME: \"backend\"\n\n  - name: \"mysql-database\"\n    helm:\n      deploymentMethod: \"native\"\n      repository: \"myorg/api-services\"\n      branchName: \"main\"\n      chart:\n        name: \"mysql\" # Using public Helm chart\n        version: \"9.14.1\"\n        repoUrl: \"https://charts.bitnami.com/bitnami\"\n        valueFiles:\n          - \"deploy/helm/mysql-values.yaml\"\n```\n\n## Templated Variables\n\nLifecycle supports template variables in Helm values that are resolved at deployment time. These variables allow you to reference dynamic values like build UUIDs, docker tags, and internal hostnames.\n\n### Available Variables\n\nTemplate variables use the format `{{{variableName}}}` and are replaced with actual values during deployment:\n\n| Variable                             | Description               | Example Value                            |\n| ------------------------------------ | ------------------------- | ---------------------------------------- |\n| `{{{serviceName_dockerTag}}}`        | Docker tag for a service  | `main-abc123`                            |\n| `{{{serviceName_dockerImage}}}`      | Full docker image path    | `registry.com/org/repo:main-abc123`      |\n| `{{{serviceName_internalHostname}}}` | Internal service hostname | `api-service.env-uuid.svc.cluster.local` |\n| `{{{build.uuid}}}`                   | Build UUID                | `env-12345`                              |\n| `{{{build.namespace}}}`              | Kubernetes namespace      | `env-12345`                              |\n\n### Usage in Values\n\n```yaml filename=\"lifecycle.yaml\"\nservices:\n  - name: web-api\n    helm:\n      deploymentMethod: \"native\"\n      chart:\n        name: \"./charts/app\"\n        values:\n          - \"image.tag={{{web-api_dockerTag}}}\"\n          - \"backend.url=http://{{{backend-service_internalHostname}}}:8080\"\n          - \"env.BUILD_ID={{{build.uuid}}}\"\n```\n\n\n**Docker Image Mapping**: When using custom charts, you'll need to map `{{{serviceName_dockerImage}}}` or `{{{serviceName_dockerTag}}}` to your chart's expected value path. Common patterns include:\n- `image.repository` and `image.tag` (most common)\n- `deployment.image` (single image string)\n- `app.image` or `application.image`\n- Custom paths specific to your chart\n\nCheck your chart's `values.yaml` to determine the correct path.\n\n\n\n#### Image Mapping Examples\n\n```yaml filename=\"lifecycle.yaml\"\n# Example 1: Separate repository and tag (most common)\nservices:\n  - name: web-api\n    helm:\n      chart:\n        name: \"./charts/standard\"\n        values:\n          - \"image.repository=registry.com/org/web-api\"    # Static repository\n          - \"image.tag={{{web-api_dockerTag}}}\"            # Dynamic tag only\n\n# Example 2: Combined image string\nservices:\n  - name: worker\n    helm:\n      chart:\n        name: \"./charts/custom\"\n        values:\n          - \"deployment.image={{{worker_dockerImage}}}\"    # Full image with tag\n\n# Example 3: Nested structure\nservices:\n  - name: backend\n    helm:\n      chart:\n        name: \"./charts/microservice\"\n        values:\n          - \"app.container.image={{{backend_dockerImage}}}\"  # Full image with tag\n```\n\n\n**Important**: Always use triple braces `{{{variable}}}` instead of double braces `{{variable}}` for Lifecycle template variables. This prevents Helm from trying to process them as Helm template functions and ensures they are passed through correctly for Lifecycle to resolve.\n\n\n### Template Resolution Order\n\n1. Lifecycle resolves `{{{variables}}}` before passing values to Helm\n2. The resolved values are then passed to Helm using `--set` flags\n3. Helm processes its own template functions (if any) after receiving the resolved values\n\n### Example with Service Dependencies\n\n```yaml filename=\"lifecycle.yaml\"\nservices:\n  - name: api-gateway\n    helm:\n      chart:\n        name: \"./charts/gateway\"\n        values:\n          - \"config.authServiceUrl=http://{{{auth-service_internalHostname}}}:3000\"\n          - \"config.userServiceUrl=http://{{{user-service_internalHostname}}}:3000\"\n          - \"image.tag={{{api-gateway_dockerTag}}}\"\n\n  - name: auth-service\n    helm:\n      chart:\n        name: \"./charts/microservice\"\n        values:\n          - \"image.tag={{{auth-service_dockerTag}}}\"\n          - \"database.host={{{postgres-db_internalHostname}}}\"\n```\n\n## Deployment Process\n\n\n  1. **Job Creation**: A Kubernetes job is created in the ephemeral namespace 2.\n  **RBAC Setup**: Service account with namespace-scoped permissions is created\n  3. **Git Clone**: Init container clones the repository 4. **Helm Deploy**:\n  Main container executes the Helm deployment 5. **Monitoring**: Logs are\n  streamed in real-time via WebSocket\n\n\n### Concurrent Deployment Handling\n\nNative Helm automatically handles concurrent deployments by:\n\n- Detecting existing deployment jobs\n- Force-deleting the old job\n- Starting the new deployment\n\nThis ensures the newest deployment always takes precedence.\n\n## Monitoring Deployments\n\n### Deploy Logs Access\n\nFor services using native Helm deployment, you can access deployment logs through the Lifecycle PR comment:\n\n1. Add the `lifecycle-status-comments!` label to your PR\n2. In the status comment that appears, you'll see a **Deploy Logs** link for each service using native Helm\n3. Click the link to view real-time deployment logs\n\n### Log Contents\n\nThe deployment logs show:\n\n- Git repository cloning progress (`clone-repo` container)\n- Helm deployment execution (`helm-deploy` container)\n- Real-time streaming of all deployment output\n- Success or failure status\n\n## Chart Types\n\nLifecycle automatically detects and handles three chart types:\n\n| Type          | Detection                                    | Features                                       |\n| ------------- | -------------------------------------------- | ---------------------------------------------- |\n| **ORG_CHART** | Matches `orgChartName` AND has `helm.docker` | Docker image injection, env var transformation |\n| **LOCAL**     | Name is \"local\" or starts with \"./\" or \"../\" | Flexible `envMapping` support                  |\n| **PUBLIC**    | Everything else                              | Standard labels and tolerations                |\n\n\n  The `orgChartName` is configured in the database's `global_config` table with\n  key `orgChart`. This allows organizations to define their standard internal\n  Helm chart.\n\n\n## Troubleshooting\n\n### Deployment Fails with \"Another Operation in Progress\"\n\n**Symptom**: Helm reports an existing operation is blocking deployment\n\n**Solution**: Native Helm automatically handles this by killing existing jobs. If the issue persists:\n\n```bash\n# Check for stuck jobs\nkubectl get jobs -n env-{uuid} -l service={serviceName}\n\n# Force delete if needed\nkubectl delete job {jobName} -n env-{uuid} --force --grace-period=0\n```\n\n### Environment Variables Not Working\n\n**Symptom**: Environment variables not passed to the deployment\n\n**Common Issues**:\n\n1. `envMapping` placed under `chart` instead of directly under `helm`\n2. Incorrect format specification (array vs map)\n3. Missing path configuration\n\n**Correct Configuration**:\n\n```yaml {4-7}\nhelm:\n  deploymentMethod: \"native\"\n  chart:\n    name: local\n  envMapping: # Correct: directly under helm\n    app:\n      format: \"array\"\n      path: \"env\"\n```\n\n## Migration Example\n\nHere's a complete example showing how to migrate from GitHub-type services to Helm-type services:\n\n### Before: GitHub-type Services\n\n```yaml filename=\"lifecycle.yaml\"\nservices:\n  - name: \"api-gateway\"\n    github:\n      repository: \"myorg/api-services\"\n      branchName: \"main\"\n      docker:\n        builder:\n          engine: \"buildkit\"\n        defaultTag: \"main\"\n        app:\n          dockerfilePath: \"docker/api.dockerfile\"\n          env:\n            BACKEND_URL: \"{{backend-service_internalHostname}}:3000\"\n            LOG_LEVEL: \"info\"\n            ENV_NAME: \"production\"\n          ports:\n            - 8080\n      deployment:\n        public: true\n        resource:\n          cpu:\n            request: \"100m\"\n          memory:\n            request: \"256Mi\"\n        readiness:\n          tcpSocketPort: 8080\n        hostnames:\n          host: \"example.com\"\n          defaultInternalHostname: \"api-gateway-prod\"\n          defaultPublicUrl: \"api.example.com\"\n\n  - name: \"backend-service\"\n    github:\n      repository: \"myorg/api-services\"\n      branchName: \"main\"\n      docker:\n        builder:\n          engine: \"buildkit\"\n        defaultTag: \"main\"\n        app:\n          dockerfilePath: \"docker/backend.dockerfile\"\n          ports:\n            - 3000\n          env:\n            NODE_ENV: \"production\"\n            SERVICE_NAME: \"backend\"\n      deployment:\n        public: false\n        resource:\n          cpu:\n            request: \"50m\"\n          memory:\n            request: \"128Mi\"\n        readiness:\n          tcpSocketPort: 3000\n\n  - name: \"mysql-database\"\n    docker:\n      dockerImage: \"mysql\"\n      defaultTag: \"8.0-debian\"\n      ports:\n        - 3306\n      env:\n        MYSQL_ROOT_PASSWORD: \"strongpassword123\"\n        MYSQL_DATABASE: \"app_database\"\n        MYSQL_USER: \"app_user\"\n        MYSQL_PASSWORD: \"apppassword456\"\n      deployment:\n        public: false\n        resource:\n          cpu:\n            request: \"100m\"\n          memory:\n            request: \"512Mi\"\n        readiness:\n          tcpSocketPort: 3306\n        serviceDisks:\n          - name: \"mysql-data\"\n            mountPath: \"/var/lib/mysql\"\n            accessModes: \"ReadWriteOnce\"\n            storageSize: \"10Gi\"\n```\n\n### After: Helm-type Services with Native Deployment\n\n```yaml filename=\"lifecycle.yaml\"\nservices:\n  - name: \"api-gateway\"\n    helm:\n      deploymentMethod: \"native\" # Enable native Helm\n      version: \"3.14.0\"\n      repository: \"myorg/api-services\"\n      branchName: \"main\"\n      args: \"--wait --timeout 10m\"\n      envMapping:\n        app:\n          format: \"array\"\n          path: \"containers.api.env\"\n      chart:\n        name: \"./charts/microservices\"\n        values:\n          - 'image.tag=\"{{{api-gateway_dockerTag}}}\"'\n          - \"service.type=LoadBalancer\"\n          - \"ingress.enabled=true\"\n        valueFiles:\n          - \"deploy/helm/base-values.yaml\"\n          - \"deploy/helm/api-gateway-values.yaml\"\n      docker:\n        builder:\n          engine: \"buildkit\"\n        defaultTag: \"main\"\n        app:\n          dockerfilePath: \"docker/api.dockerfile\"\n          env:\n            BACKEND_URL: \"{{backend-service_internalHostname}}:3000\"\n            LOG_LEVEL: \"info\"\n            ENV_NAME: \"production\"\n          ports:\n            - 8080\n\n  - name: \"backend-service\"\n    helm:\n      deploymentMethod: \"native\"\n      version: \"3.14.0\"\n      repository: \"myorg/api-services\"\n      branchName: \"main\"\n      envMapping:\n        app:\n          format: \"map\" # Using map format for this service\n          path: \"env\"\n      chart:\n        name: \"./charts/microservices\"\n        values:\n          - 'image.tag=\"{{{backend-service_dockerTag}}}\"'\n          - \"replicaCount=2\"\n        valueFiles:\n          - \"deploy/helm/base-values.yaml\"\n          - \"deploy/helm/backend-values.yaml\"\n      docker:\n        builder:\n          engine: \"buildkit\"\n        defaultTag: \"main\"\n        app:\n          dockerfilePath: \"docker/backend.dockerfile\"\n          ports:\n            - 3000\n          env:\n            NODE_ENV: \"production\"\n            SERVICE_NAME: \"backend\"\n\n  - name: \"mysql-database\"\n    helm:\n      deploymentMethod: \"native\"\n      repository: \"myorg/api-services\"\n      branchName: \"main\"\n      chart:\n        name: \"mysql\" # Using public Helm chart\n        version: \"9.14.1\"\n        repoUrl: \"https://charts.bitnami.com/bitnami\"\n        valueFiles:\n          - \"deploy/helm/mysql-values.yaml\"\n```\n\n### Key Migration Points\n\n1. **Service Type Change**: Changed from `github:` to `helm:` configuration\n2. **Repository Location**: `repository` and `branchName` move from under `github:` to directly under `helm:`\n3. **Deployment Method**: Added `deploymentMethod: \"native\"` to enable native Helm\n4. **Chart Configuration**: Added `chart:` section with local or public charts\n5. **Environment Mapping**: Added `envMapping:` to control how environment variables are passed\n6. **Helm Arguments**: Added `args:` for Helm command customization\n7. **Docker Configuration**: Kept existing `docker:` config for build process\n\n\n  Note that when converting from GitHub-type to Helm-type services, the\n  `repository` and `branchName` fields move from being nested under `github:` to\n  being directly under `helm:`.\n\n\n\n  Many configuration options (like Helm version, args, and chart details) can be\n  defined in the `global_config` database table, making the service YAML\n  cleaner. Only override when needed."
  },
  {
    "title": "Template Variables",
    "description": null,
    "date": null,
    "path": "docs/features/template-variables",
    "body": "## Overview\n\nLifecycle uses [Mustache](https://github.com/janl/mustache.js) as the template rendering engine.\n\n## Available Template Variables\n\nThe following template variables are available for use within your configuration. Variables related to specific services should use the service name as a prefix.\n\n### General Variables\n\n- **`{{{buildUUID}}}`** - The unique identifier for the Lifecycle environment, e.g., `lively-down-881123`.\n- **`{{{namespace}}}`** - Namespace for the deployments, e.g., `env-lively-down-881123`.\n- **`{{{pullRequestNumber}}}`** - The GitHub pull request number associated with the environment.\n\n### Service-Specific Variables\n\nFor service-specific variables, replace `` with the actual service name.\n\n- **`{{{_internalHostname}}}`** - The internal hostname of the deployed service. If the service is optional and not deployed, it falls back to `defaultInternalHostname`.\n\n  \n    `service_internalHostname` will be substituted with local cluster full\n    domain name like `service.namespace.svc.cluster.local` to be able to work\n    with deployments across namespaces.\n  \n\n- **`{{{_publicUrl}}}`** - The public URL of the deployed service. If optional and not deployed, it defaults to `defaultPublicUrl` under the `services` table.\n- **`{{{_sha}}}`** - The GitHub SHA that triggered the Lifecycle build.\n- **`{{{_branchName}}}`** - The branch name of the pull request that deployed the environment.\n- **`{{{_UUID}}}`** - The build UUID of the service. If listed under `optionalServices` or `defaultServices`, its value depends on whether the service is selected:\n  - If selected, it is equal to `buildUUID`.\n  - If not selected (or if service not part of deploys created), it defaults to **`dev-0`**.\n\n## Usage Example\n\n```yaml\nservices:\n  frontend:\n    # ...\n    env:\n      API_URL: \"{{{backend_publicUrl}}}\"\n      UUID: \"{{{buildUUID}}}\"\n```\n\nThis ensures the `PUBLIC_URL` and `INTERNAL_HOST` variables are dynamically assigned based on the ephemeral environment deployment.\n\n \n- Undefined variables will result in an empty string unless handled explicitly.\n- Use triple curly braces (`{{{ }}}`) to prevent unwanted HTML escaping.\n- Ensure service names are correctly referenced in the template without any spaces.\n\n\nFor more details, refer to the [Mustache.js documentation](https://github.com/janl/mustache.js)."
  },
  {
    "title": "Service Dependencies",
    "description": "Understand service dependencies, their impact, and configuration.",
    "date": "2025-02-16",
    "path": "docs/features/service-dependencies",
    "body": "This document will cover `environment.{defaultServices,optionalServices}` and `service.requires`, their differences, impact scope, and usage.\n\n## `environment.{defaultServices,optionalServices}`\n\n### Impact scope\n\n| Scope                     | Impact |\n| ------------------------- | ------ |\n| Service repo\\* | ‚úÖ     |\n| Outside repo\\* | ‚ùå     |\n| dev-0\\*        | ‚ùå     |\n\nThis represents the default environment that will be created by lifecycle when a pull request is opened in the service repo\\* and does not have any impact on outside repos, dev-0, or any other static environments that use this service.\n\n## `services.requires`\n\n### Impact scope\n\n| Scope                     | Impact |\n| ------------------------- | ------ |\n| Service repo\\* | ‚úÖ     |\n| Outside repo\\* | ‚úÖ     |\n| dev-0\\*        | ‚úÖ     |\n\n`services.requires` has an impact across the board; hence, it is important to understand how it works and when we should use them.\n\n**Please read the info blocks below carefully.**\n\nYou can think of `services.requires` as a hard dependency definition. For example, if you have an API service and a database, the API service will have a hard dependency on the database.\nIn this scenario, the database should not be defined as the default service. Instead, we should make the dependency explicitly clear by adding the database to the API‚Äôs `requires` block.\nBy doing this, we ensure that any outside repo that wants to use our API service will get the database along with it but only needs to specify the API service in their `defaultServices` or `optionalServices`.\n\n\n  Only services defined in `lifecycle.yaml` should be used in the `requires`\n  array. If a service is defined in an outside repo, use\n  `environment.defaultServices` instead.\n\n\nDo not use services in the `services.requires` if the service itself is not\ndefined in the same lifecycle.yaml.\n\n\n  Services defined in the `requires` block will only be resolved 1 level down.\n\n\n**This is a very important nuance, which we get tripped by regularly.**\n\n---\n\n## Examples\n\nTo better illustrate the above statement, consider this example.\n\nRepository A `r-A` has 3 services `s-A`, `s-B`, and `s-C`.\n\n- `s-A` requires `s-B`.\n- `s-B` requires `s-C`.\n\nAs you can see, `s-A` has an indirect dependency on `s-C` through `s-B`.\n\n### Scenario 1: Pull Request in Service repo\\* ‚úÖ\n\nWhen we open a pull request in `r-A` repo, lifecycle will deploy 3 services: `s-A`, `s-B`, and `s-C`.\n\n#### Breakdown\n\n- Lifecycle deploys `s-A` and `s-B` because they are defined in `defaultServices`.\n- Services defined in the `requires` block will only be resolved **one level down**.\n- Only services defined in `lifecycle.yaml` should be used in the `requires` array. If a service is defined in an outside repo, use `environment.defaultServices` instead.\n\n```yaml\n# `r-A.lifecycle.yaml`\nenvironment:\n  defaultServices:\n    - name: \"s-A\"\n    - name: \"s-B\"\n\nservices:\n  - name: \"s-A\"\n    requires:\n      - name: \"s-B\"\n    helm: ...\n\n  - name: \"s-B\"\n    requires:\n      - name: \"s-C\"\n    helm: ...\n\n  - name: \"s-C\"\n    helm: ...\n```\n\n### Scenario 2: ‚ùå\n\nRepository B `r-B` has service `s-X` and also defines an outside repo `r-A` service `s-A` as `environment.defaultServices`.\n\n```yaml\n#  `r-B.lifecycle.yaml`\nenvironment:\n  defaultServices:\n    - name: \"s-X\"\n    - name: \"s-A\"\n      repository: \"lifecycle/r-A\"\n      branch: \"main\"\n\nservices:\n  - name: \"s-X\"\n    helm: ...\n```\n\n#### Breakdown\n\n1. Lifecycle deploys `s-X` and `s-A` because they are defined in `defaultServices`.\n2. Lifecycle deploys `s-B` because it is a 1st level dependency of a service (`s-A`) listed in `defaultServices`.\n3. Lifecycle **does not** deploy `s-C` since it is **not** a 1st level dependency of any service listed in `defaultServices` or `optionalServices`.\n\nThe way this scenario manifests is lifecycle will deploy `s-X`, `s-A`, and `s-B`, but the build will likely **fail** because `s-B` is missing a required dependency `s-C`.\n\n### Solutions\n\nThere are 2 ways to address this depending on your use case.\n\n#### Solution 1\n\nAdd `s-B` to `r-B`‚Äôs `environment.defaultServices` block in `r-B.lifecycle.yaml`. In effect, this will make `s-C` a first-level dependency.\n\n```yaml\nenvironment:\n  defaultServices:\n    - name: \"s-X\"\n    - name: \"s-A\"\n      repository: \"lifecycle/r-A\"\n      branch: \"main\"\n    - name: \"s-B\"\n      repository: \"lifecycle/r-A\"\n      branch: \"main\"\n```\n\n#### Solution 2\n\nAdd `s-C` to the `services.requires` block of `r-A` in `r-A.lifecycle.yaml`. This will also make `s-C` a first-level dependency.\n\n```yaml\nenvironment:\n  defaultServices:\n    - name: \"s-A\"\n    - name: \"s-B\"\n\nservices:\n  - name: \"s-A\"\n    requires:\n      - name: \"s-B\"\n      - name: \"s-C\"\n    helm: ...\n```\n\n### Choosing the Right Solution\n\nIn summary, the solution you should use depends on how you want your service to be consumed in an outside repo\\*.\n\n- If you want outside repos to explicitly include `s-A` and `s-B`, use **Solution 1**.\n- If you want outside repos to only include `s-A` and let dependencies resolve automatically, use **Solution 2**.\n\n---\n\n### Terminology\n\n- **Service repo**: The repository where `lifecycle.yaml` is defined.\n- **Outside repo**: Another repository referencing it.\n- **dev-0**: Default static environment."
  },
  {
    "title": "Install Lifecycle",
    "description": null,
    "date": null,
    "path": "docs/setup/install-lifecycle",
    "body": "Now that the infrastructure components are setup, let's install the lifecycle app and create a new Github app that will send events to the application to process and create ephemeral dev environments.\n\n\n  Make sure you have updated the kube config to be able to `helm install` in the\n  cluster you just created!\n\n\n- Clone the repository:\n\n```sh\ngit clone https://github.com/GoodRxOSS/lifecycle\ncd lifecycle\n```\n\n- Install the Lifecycle Helm chart:\n\n```sh\nhelm upgrade -i lifecycle helm/web-app --namespace lifecycle-app --values ./helm/environments/default/lifecycle.yaml --set components.web.ingress.hosts\\[0\\].host=app.\n```\n\n\n  Make sure to replace values with your actual domain.\n\n\n- Wait for the installation to complete and verify that the pods are running:\n\n```sh\nkubectl get pods -n lifecycle-app\n```\n\n- Once the pods are running, you can access the application at your configured domain (e.g. `https://app.0env.com`)\n\n\n\nJust like that, you have successfully installed Lifecycle and set up the necessary infrastructure to start creating ephemeral environments for your GitHub pull requests!\n\nIf you notice any secure certificate issues when accessing the application, you can check the status of your certificate using the following command:\n\n```sh\nkubectl get certificate -n lifecycle-app\n```\n\n\n\nMake sure the certificate is in the `Ready` state. If it is not, you may need to wait a bit longer for the certificate to be issued or troubleshoot any issues with your DNS settings.\n\nLet's move on to the next step where we will create a GitHub app to connect Lifecycle with your repositories."
  },
  {
    "title": "Prerequisites",
    "description": null,
    "date": null,
    "path": "docs/setup/prerequisites",
    "body": "Before we start with the setup, let's make sure the following prerequisites are in place:\n\n- **GitHub Account**: You'll need either a personal or an organization GitHub account. [Sign up for GitHub](https://github.com/join)\n\n- **Cloud Provider Account**: A Google Kubernetes Engine (GKE) or Amazon Web Services (AWS) Account. You'll need an active account with either platform to proceed.\n  - [Sign up for Google Cloud](https://cloud.google.com) and create a project\n  - [Sign up for AWS](https://aws.amazon.com/)\n\n\n  We recommend using an isolated project or account in your cloud provider\n  specifically for this setup to begin with. This helps to keep your resources\n  organized and manageable as you experiment with Lifecycle.\n\n\n- **CLI Tools**\n\n  - **[OpenTofu](https://opentofu.org/docs/intro/install/)** ‚Äî Infrastructure as code tool (OpenTofu is a community-driven fork of Terraform).\n  - **[kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl)** ‚Äî Command-line tool for interacting with Kubernetes clusters.\n  - **[gcloud](https://formulae.brew.sh/cask/google-cloud-sdk)** or **[aws-cli](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)** ‚Äî Command-line tools for managing Google Cloud or AWS resources, respectively.\n\n- **Custom Domain**: You will need a custom domain (e.g., `0env.com`) to route traffic to your application environments. This is particularly important for setting up:\n\n  - Public callback and webhook URLs for the GitHub App\n  - Ingress routing within the Kubernetes cluster\n  - Secure (HTTPS) access via TLS certificates\n\n- **DNS Provider with Wildcard Support**: The domain must be managed by a DNS provider that supports wildcard DNS records (e.g., \\*.0env.com). This is necessary to dynamically route traffic from GitHub to the Lifecycle app and to ephemeral environments.\n\n  Supported DNS providers that support wildcard for infrastructure setup include:\n\n\n\n  \n  **Manual Setup**:\n        Setup a [public DNS zone in Google Cloud](https://cloud.google.com/dns) to manage your domain's DNS records.\n\n      - Follow steps [here](https://cloud.google.com/dns/docs/zones#create-pub-zone) to setup a\n      public DNS zone.\n\n      - Wildcard DNS records will be created by the OpenTofu modules in the next steps.\n\n**CLI Setup**:\nUse the `gcloud` CLI to create a public DNS zone for your domain:\n\n```sh\ngcloud config set project \ngcloud auth application-default login\ngcloud services enable dns.googleapis.com --project=\ngcloud dns --project= managed-zones create  --description=\"Lifecycle OSS starter DNS public zone\" --dns-name=\".\" --visibility=\"public\" --dnssec-state=\"off\"\n```\n\n_Update your domain's DNS records with NS records provided by Google Cloud DNS. You can find these in the Google Cloud Console under the DNS zone you created._\n\n  \n\n\n  **[AWS Route 53](https://aws.amazon.com/route53/)**: Amazon's scalable DNS web\n  service designed to route end users to Internet applications.\n\n  **Manual Setup**:\n\n  - Authenticate with AWS CLI using the role/usr you desire.\n  - Ensure you have [your domain provisioned to accept wildcards](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/CreatingNewSubdomain.html); eg `*.lifecycle..com`\n\n  **CLI Setup**:\n\n  ```sh\n  aws configure\n  ```\n\n  ```sh\n  aws route53 change-resource-record-sets --hosted-zone-id  --change-batch '{\n    \"Comment\": \"CREATE wildcard for \",\n    \"Changes\": [\n      {\n        \"Action\": \"CREATE\",\n        \"ResourceRecordSet\": {\n          \"Name\": \"..com\",\n          \"Type\": \"A\",\n          \"TTL\": 300,\n          \"ResourceRecords\": [\n            {\n              \"Value\": \"*********\"\n            }\n          ]\n        }\n      }\n    ]\n  }'\n  ```\n\n\n\n\n  If you want to use Cloudflare as your primary DNS provider and manage your DNS records on Cloudflare, your domain should be using a full setup.\n  This means that you are using Cloudflare for your authoritative DNS nameservers.\n  Follow the steps [here](https://developers.cloudflare.com/dns/zone-setups/full-setup/setup/) to setup a public DNS zone in Cloudflare.\n\n\n\n\n---\n\n\n  Ensure that your domain‚Äôs nameservers are pointing to your chosen DNS provider\n  at your registrar, and that you have permission to create and manage DNS\n  records programmatically.  **This is crucial for the setup to work\n  correctly and will take time to propagate.**\n\nUse https://dnschecker.org/#NS to verify that your domain's nameservers are correctly set up.\n\n\n\nOnce you have these prerequisites in place, you can proceed to the next steps in setting up the cluster and application."
  },
  {
    "title": "Setup your cluster",
    "description": null,
    "date": null,
    "path": "docs/setup/setup-infra",
    "body": "Based on the prerequisites you've set up, you're now ready to configure your Kubernetes cluster for Lifecycle. This setup will ensure that your cluster is properly configured to run Lifecycle and manage your application environments effectively.\n\n\n  Note that the infra setup with the OpenTofu modules below will **open your\n  cluster to the world.** \n  üõ°Ô∏è Make sure to **shield** your cluster by implementing appropriate network policies\n  and access controls after the initial setup.\n\n\n\nClick on the cloud provider you are using to set up your cluster:\n\n- [Google Cloud Platform (GCP)](#google-cloud-platform)\n- [Amazon Web Services (AWS)](#amazon-web-services)\n\n## Google Cloud Platform\n\n### Setup application credentials\n\n```sh\n# setup current project\ngcloud config set project \n# creates the application default credentials\ngcloud auth application-default login\n```\n\nEnable Kubernetes Engine and Cloud DNS APIs:\n\n```sh\ngcloud services enable container.googleapis.com --project=\ngcloud services enable dns.googleapis.com --project=\n```\n\n\n  Note that you need to replace `` with your actual Google Cloud project ID not the project name.\n\n\n### Bootstrap infrastructure\n\n- Clone the infrastructure repository:\n\n```sh\ngit clone https://github.com/GoodRxOSS/lifecycle-opentofu/\ncd lifecycle-opentofu\n```\n\n- Follow steps in the [infrastructure repository](https://github.com/GoodRxOSS/lifecycle-opentofu/?tab=readme-ov-file#%EF%B8%8F-quick-start) to set up the necessary infrastructure components.\n\n```sh\ncp example.auto.tfvars secrets.auto.tfvars\n```\n\nExample `secrets.auto.tfvars` file:\n\n```hcl secrets.auto.tfvars\ngcp_project          = \"\"\ngcp_region           = \"\"\n# this is the default credentials file created by gcloud cli\ngcp_credentials_file = \"~/.config/gcloud/application_default_credentials.json\"\ncluster_provider     = \"gke\"\ndns_provider         = \"cloud-dns\"     # [cloudflare|route53|cloud-dns]\napp_domain           = \"\" # e.g. 0env.com\n\ncluster_name         = \"lifecycle-gke\" # change this to your preferred cluster name\napp_namespace        = \"lifecycle-app\" # use default namespace\n```\n\n- Initialize and apply the Terraform configuration:\n\n```sh\ntofu init\ntofu plan\ntofu apply\n```\n\nThis will create the necessary infrastructure components, including the Kubernetes cluster, DNS records, database, redis and other resources required for Lifecycle to function properly.\n\nAfter the Terraform apply completes, you should have a fully functional Kubernetes cluster with the necessary resources set up.\n\nLet's test the public DNS setup by accessing the test application deployed called `kuard` and follow the rest of the setup instructions from the `tofu apply` output.\n\n```sh\ncurl -v https://kuard.0env.com  # replace with your domain\n```\n\nRefer example output [here](https://github.com/GoodRxOSS/lifecycle-opentofu/?tab=readme-ov-file#4-initialize--apply) to setup kubeconfig and access the cluster using `kubectl`.\n\nNow that your cluster is set up, you can proceed to installing Lifecycle application to your cluster.\n\n\n}\n  title=\"Install Lifecycle\"\n  href=\"/docs/setup/install-lifecycle\"\n  arrow\n/>\n\n---\n\n## Amazon Web Services\n\n```sh\n# setup current project\naws configure --profile lifecycle-oss-eks\nAWS Access Key ID [***]: \nAWS AWS Secret Access Key [***]: \nDefault Region name: \nDefault output format: \n```\n\n\\*This profile needs to have access a user with `AdministratorAccess` access.\n\n---\n\n### Bootstrap infrastructure\n\n- Clone the infrastructure repository:\n\n```sh\ngit clone https://github.com/GoodRxOSS/lifecycle-opentofu/\ncd lifecycle-opentofu\n```\n\n- Follow steps in the [infrastructure repository](https://github.com/GoodRxOSS/lifecycle-opentofu/?tab=readme-ov-file#%EF%B8%8F-quick-start) to set up the necessary infrastructure components.\n\n```sh\ncp example.auto.tfvars secrets.auto.tfvars\n```\n\nExample `secrets.auto.tfvars` file:\n\n```hcl secrets.auto.tfvars\n# gcp_project          = \"\"\n$ gcp_region           = \"\"\n# this is the default credentials file created by gcloud cli\n# gcp_credentials_file = \"~/.config/gcloud/application_default_credentials.json\"\ncluster_provider     = \"aws\"\ndns_provider         = \"route53\"     # [cloudflare|route53|cloud-dns]\napp_domain           = \"example.com\" # e.g. 0env.com\n\ncluster_name         = \"lifecycle-eks\" # change this to your preferred cluster name\napp_namespace        = \"lifecycle-app\" # use default namespace\n```\n\n- Initialize and apply the Terraform configuration:\n\n```sh\ntofu init\ntofu plan\ntofu apply\n```\n\nThis will create the necessary infrastructure components, including the Kubernetes cluster, DNS records, database, redis and other resources required for Lifecycle to function properly.\n\nAfter the Terraform apply completes, you should have a fully functional Kubernetes cluster with the necessary resources set up.\n\nLet's test the public DNS setup by accessing the test application deployed called `kuard` and follow the rest of the setup instructions from the `tofu apply` output.\n\n```sh\ncurl -v https://kuard.0env.com  # replace with your domain\n```\n\nRefer example output [here](https://github.com/GoodRxOSS/lifecycle-opentofu/?tab=readme-ov-file#4-initialize--apply) to setup kubeconfig and access the cluster using `kubectl`.\n\nNow that your cluster is set up, you can proceed to installing Lifecycle application to your cluster.\n\n\n}\n  title=\"Install Lifecycle\"\n  href=\"/docs/setup/install-lifecycle\"\n  arrow\n/>"
  },
  {
    "title": "Additional Configuration",
    "description": null,
    "date": null,
    "path": "docs/setup/configure-lifecycle",
    "body": "We are in the final step of the setup process.\n\n**This step is Optional but highly recommended to ensure the default IP Whitelist is set for the environments created by the Lifecycle app.** This will help in securing the environments and restricting access to only the specified IPs or CIDR blocks.\n\n## Set Default IP Whitelist\n\n- Connect to the `postgres` database using the `psql` command line tool or any other database client.\n\n  \n\n  Database password was auto generated during the infra setup and can be found\n  retrieved from the `app-postgres` secret in the `lifecycle-app`\n  namespace.\n\n  \n\n- Retrieve the database password:\n\n```sh\n   kubectl get secret app-postgres --namespace lifecycle-app \\\n      -o jsonpath='{.data}' | jq 'with_entries(.value |= @base64d)'\n```\n\n- Run the following SQL commands to update the configuration:\n\n```sql\n-- provide a default IP whitelist for the environments, default is open to all IPs\nUPDATE public.global_config\nSET\n    config = (\n        config::jsonb ||\n        '{\n            \"defaultIPWhiteList\": \"{ 0.0.0.0/0 }\"\n         }'::jsonb\n    )::json,\n    \"updatedAt\" = NOW()\nWHERE \"key\" = 'serviceDefaults';\n```\n\n\n  Note that the infra setup with the OpenTofu modules below will **open your\n  cluster to the world.** \n  üõ°Ô∏è Make sure to **shield** your cluster by implementing appropriate network policies\n  and access controls after the initial setup.\n\nReplace the `defaultIPWhiteList` under `global_config.serviceDefaults` with your actual IP whitelist or CIDR block to restrict access to the deployed environments.\n\n\n\n---\n\n## Refresh config cache\n\n```sh\ncurl -X PUT https://app./api/v1/config/cache\n```\n\nThis will refresh the configuration cache and apply the changes you made to the database for the Lifecycle app.\n\nWe are all set! üéâ And ready to create our first PR based ephemeral environment."
  },
  {
    "title": "Configure Application",
    "description": null,
    "date": null,
    "path": "docs/setup/create-github-app",
    "body": "To create a Github app that will send events to the Lifecycle with necessary permissions, follow these steps:\n\n\n  Make sure you have admin access to the Github organization or account where\n  you want to create the app.\n\n\n- Navigate to your installed Lifecycle app at `https://app./setup` (replace `` with your actual domain. e.g. `https://app.0env.com/setup`).\n  \n- Select `Personal` or `Organization` based on your needs.\n- Fill in the required fields:\n\n  - **Github App Name**: A name for your app. (should be unique, use a prefix with your name or organization. Refer Github app naming convention [here](https://docs.github.com/en/apps/creating-github-apps/registering-a-github-app/)\n  - **Organization Name**: Github organization name where the app will be created. Required if you selected `Organization`.\n\n- Click `Create App`\n- On the Github app creation page, confirm the app name and click `Create`\n- Once the app is created, you will be redirected to the app installation page where you can choose one or more repositories to install the the newly minted app.\n\n  \n    Make sure to select the repositories you want the app to have access to. You\n    can always change this later in the app settings but **adding atleast one\n    repository is required to proceed with the setup**.\n  \n\n  \n\n- Voila! üéâ Your Github app is now created and installed.\n\n\n\n- Click `Configure and Restart` to apply the changes and start using the app.\n\n\n  The step above, sets up the global config values that Lifecycle app will use\n  creating ephemeral environments and processing pull requests. And restarts the\n  `deployment` for the github app secrets to take effect.\n\n\n---\n\nLet's move on the final step where we will configure the Lifecycle app config for processing pull requests and creating ephemeral environments."
  },
  {
    "title": "Deploy Issues",
    "description": "Understand how to handle common deploy issues with environments",
    "date": "2025-03-11",
    "path": "docs/troubleshooting/deploy-issues",
    "body": "TODO: This document will cover common deploy issues that you may encounter\n  when working with Lifecycle environments."
  },
  {
    "title": "Missing PR comment",
    "description": null,
    "date": null,
    "path": "docs/troubleshooting/github-app-webhooks",
    "body": "Let's quickly validate that the app is able to send events to the Lifecycle app successfully.\n\n- Navigate to your Github app\n- Click `App Settings` link in the Github application page\n- Choose `Advanced` from the left sidebar\n- `Recent Deliveries` section should show a successful delivery of the `installation` event to the Lifecycle app.\n\n  \n    If you see an error or no deliveries, make sure the app is installed in the\n    atleast one repository and that the webhook URL is set correctly by\n    navigating to the `General` section from the left sidebar and checking the\n    `Webhook URL` field.\n  \n\n- If the delivery is successful, you should see a status code of `200 OK`\n\n## Failing deliveries\n\nIf you see a delivery failure, it could be due to various reasons. Here are some common issues and how to resolve them:\n\n### Github App secrets\n\n- Make sure that the Github App secrets are correctly set in the `lifecycle-app` namespace. You can verify this by running the following command:\n\n```sh\nkubectl get secret app-secrets --namespace lifecycle-app \\\n      -o jsonpath='{.data}' | jq 'with_entries(.value |= @base64d)'\n```\n\n- The output should include all the `GITHUB_*` variables with the correct values.\n\n- If the secrets are present but the delivery is still failing, try restarting the following deployments.\n\n```sh\n kubectl rollout restart  deployment lifecycle-web lifecycle-worker -n lifecycle-app\n```\n\n- Try triggering a new event (create a pull request) by making a change in the repository or by manually redelivering a failed delivery."
  },
  {
    "title": "Troubleshooting Build Issues",
    "description": "Understand how to handle common build issues with environments",
    "date": null,
    "path": "docs/troubleshooting/build-issues",
    "body": "TODO: This document will cover common build issues that you may encounter when\n  working with Lifecycle environments."
  },
  {
    "title": "Lifecycle Full Schema",
    "description": "Lifecycle Schema documentation; this page contains the full schema as defined in lifecycle core‚Äîall at once.",
    "date": "2025-05-31",
    "path": "docs/schema/full",
    "body": "## Full Lifecycle Schema\n\nBelow is the full Lifecycle schema as defined in the `lifecycle.yaml` file with basic comments for each item.\n\n```yaml\n# @section environment\nenvironment:\n  # @param environment.autoDeploy\n  autoDeploy: false\n  # @param environment.useGithubStatusComment\n  useGithubStatusComment: false\n  # @param environment.defaultServices\n  defaultServices:\n    # @param environment.defaultServices[]\n    - # @param environment.defaultServices.name (required)\n      name: \"\"\n      # @param environment.defaultServices.repository\n      repository: \"\"\n      # @param environment.defaultServices.branch\n      branch: \"\"\n  # @param environment.optionalServices\n  optionalServices:\n    # @param environment.optionalServices[]\n    - # @param environment.optionalServices.name (required)\n      name: \"\"\n      # @param environment.optionalServices.repository\n      repository: \"\"\n      # @param environment.optionalServices.branch\n      branch: \"\"\n\n# @section services\nservices:\n  # @param services[]\n  - # @param services.name (required)\n    name: \"\"\n    # @param services.appShort\n    appShort: \"\"\n    # @param services.defaultUUID\n    defaultUUID: \"\"\n    # @param services.github\n    github:\n      # @param services.github.repository (required)\n      repository: \"\"\n      # @param services.github.branchName (required)\n      branchName: \"\"\n      # @param services.github.docker (required)\n      docker:\n        # @param services.github.docker.defaultTag (required)\n        defaultTag: \"\"\n        # @param services.github.docker.pipelineId\n        pipelineId: \"\"\n        # @param services.github.docker.ecr\n        ecr: \"\"\n        # @param services.github.docker.app (required)\n        app:\n          # @param services.github.docker.app.afterBuildPipelineConfig\n          afterBuildPipelineConfig:\n            # @param services.github.docker.app.afterBuildPipelineConfig.afterBuildPipelineId\n            afterBuildPipelineId: \"\"\n            # @param services.github.docker.app.afterBuildPipelineConfig.detatchAfterBuildPipeline\n            detatchAfterBuildPipeline: false\n            # @param services.github.docker.app.afterBuildPipelineConfig.description\n            description: \"\"\n          # @param services.github.docker.app.dockerfilePath (required)\n          dockerfilePath: \"\"\n          # @param services.github.docker.app.command\n          command: \"\"\n          # @param services.github.docker.app.arguments\n          arguments: \"\"\n          # @param services.github.docker.app.env\n          env:\n\n          # @param services.github.docker.app.ports\n          ports:\n            # @param services.github.docker.app.ports[]\n            - \"\"\n        # @param services.github.docker.init\n        init:\n          # @param services.github.docker.init.dockerfilePath (required)\n          dockerfilePath: \"\"\n          # @param services.github.docker.init.command\n          command: \"\"\n          # @param services.github.docker.init.arguments\n          arguments: \"\"\n          # @param services.github.docker.init.env\n          env:\n\n        # @param services.github.docker.builder\n        builder:\n          # @param services.github.docker.builder.engine\n          engine: \"\"\n      # @param services.github.deployment\n      deployment:\n        # @param services.github.deployment.helm\n        helm:\n          # @param services.github.deployment.helm.enabled\n          enabled: false\n          # @param services.github.deployment.helm.chartName\n          chartName: \"\"\n          # @param services.github.deployment.helm.chartRepoUrl\n          chartRepoUrl: \"\"\n          # @param services.github.deployment.helm.chartVersion\n          chartVersion: \"\"\n          # @param services.github.deployment.helm.cmdPs\n          cmdPs: \"\"\n          # @param services.github.deployment.helm.action\n          action: \"\"\n          # @param services.github.deployment.helm.customValues\n          customValues:\n            # @param services.github.deployment.helm.customValues[]\n            - \"\"\n          # @param services.github.deployment.helm.customValueFiles\n          customValueFiles:\n            # @param services.github.deployment.helm.customValueFiles[]\n            - \"\"\n          # @param services.github.deployment.helm.helmVersion\n          helmVersion: \"\"\n          # @param services.github.deployment.helm.attachPvc\n          attachPvc:\n            # @param services.github.deployment.helm.attachPvc.enabled\n            enabled: false\n            # @param services.github.deployment.helm.attachPvc.mountPath\n            mountPath: \"\"\n        # @param services.github.deployment.public\n        public: false\n        # @param services.github.deployment.capacityType\n        capacityType: \"\"\n        # @param services.github.deployment.resource\n        resource:\n          # @param services.github.deployment.resource.cpu\n          cpu:\n            # @param services.github.deployment.resource.cpu.request\n            request: \"\"\n            # @param services.github.deployment.resource.cpu.limit\n            limit: \"\"\n          # @param services.github.deployment.resource.memory\n          memory:\n            # @param services.github.deployment.resource.memory.request\n            request: \"\"\n            # @param services.github.deployment.resource.memory.limit\n            limit: \"\"\n        # @param services.github.deployment.readiness\n        readiness:\n          # @param services.github.deployment.readiness.disabled\n          disabled: false\n          # @param services.github.deployment.readiness.tcpSocketPort\n          tcpSocketPort: 0\n          # @param services.github.deployment.readiness.httpGet\n          httpGet:\n            # @param services.github.deployment.readiness.httpGet.path\n            path: \"\"\n            # @param services.github.deployment.readiness.httpGet.port\n            port: 0\n          # @param services.github.deployment.readiness.initialDelaySeconds\n          initialDelaySeconds: 0\n          # @param services.github.deployment.readiness.periodSeconds\n          periodSeconds: 0\n          # @param services.github.deployment.readiness.timeoutSeconds\n          timeoutSeconds: 0\n          # @param services.github.deployment.readiness.successThreshold\n          successThreshold: 0\n          # @param services.github.deployment.readiness.failureThreshold\n          failureThreshold: 0\n        # @param services.github.deployment.hostnames\n        hostnames:\n          # @param services.github.deployment.hostnames.host\n          host: \"\"\n          # @param services.github.deployment.hostnames.acmARN\n          acmARN: \"\"\n          # @param services.github.deployment.hostnames.defaultInternalHostname\n          defaultInternalHostname: \"\"\n          # @param services.github.deployment.hostnames.defaultPublicUrl\n          defaultPublicUrl: \"\"\n        # @param services.github.deployment.network\n        network:\n          # @param services.github.deployment.network.ipWhitelist\n          ipWhitelist:\n            # @param services.github.deployment.network.ipWhitelist[]\n            - \"\"\n          # @param services.github.deployment.network.pathPortMapping\n          pathPortMapping:\n\n          # @param services.github.deployment.network.hostPortMapping\n          hostPortMapping:\n\n          # @param services.github.deployment.network.grpc\n          grpc:\n            # @param services.github.deployment.network.grpc.enable\n            enable: false\n            # @param services.github.deployment.network.grpc.host\n            host: \"\"\n            # @param services.github.deployment.network.grpc.defaultHost\n            defaultHost: \"\"\n        # @param services.github.deployment.serviceDisks\n        serviceDisks:\n          # @param services.github.deployment.serviceDisks[]\n          - # @param services.github.deployment.serviceDisks.name (required)\n            name: \"\"\n            # @param services.github.deployment.serviceDisks.mountPath (required)\n            mountPath: \"\"\n            # @param services.github.deployment.serviceDisks.accessModes\n            accessModes: \"\"\n            # @param services.github.deployment.serviceDisks.storageSize (required)\n            storageSize: \"\"\n            # @param services.github.deployment.serviceDisks.medium\n            medium: \"\"\n    # @param services.docker\n    docker:\n      # @param services.docker.dockerImage (required)\n      dockerImage: \"\"\n      # @param services.docker.defaultTag (required)\n      defaultTag: \"\"\n      # @param services.docker.command\n      command: \"\"\n      # @param services.docker.arguments\n      arguments: \"\"\n      # @param services.docker.env\n      env:\n\n      # @param services.docker.ports\n      ports:\n        # @param services.docker.ports[]\n        - \"\"\n      # @param services.docker.deployment\n      deployment:\n        # @param services.docker.deployment.helm\n        helm:\n          # @param services.docker.deployment.helm.enabled\n          enabled: false\n          # @param services.docker.deployment.helm.chartName\n          chartName: \"\"\n          # @param services.docker.deployment.helm.chartRepoUrl\n          chartRepoUrl: \"\"\n          # @param services.docker.deployment.helm.chartVersion\n          chartVersion: \"\"\n          # @param services.docker.deployment.helm.cmdPs\n          cmdPs: \"\"\n          # @param services.docker.deployment.helm.action\n          action: \"\"\n          # @param services.docker.deployment.helm.customValues\n          customValues:\n            # @param services.docker.deployment.helm.customValues[]\n            - \"\"\n          # @param services.docker.deployment.helm.customValueFiles\n          customValueFiles:\n            # @param services.docker.deployment.helm.customValueFiles[]\n            - \"\"\n          # @param services.docker.deployment.helm.helmVersion\n          helmVersion: \"\"\n          # @param services.docker.deployment.helm.attachPvc\n          attachPvc:\n            # @param services.docker.deployment.helm.attachPvc.enabled\n            enabled: false\n            # @param services.docker.deployment.helm.attachPvc.mountPath\n            mountPath: \"\"\n        # @param services.docker.deployment.public\n        public: false\n        # @param services.docker.deployment.capacityType\n        capacityType: \"\"\n        # @param services.docker.deployment.resource\n        resource:\n          # @param services.docker.deployment.resource.cpu\n          cpu:\n            # @param services.docker.deployment.resource.cpu.request\n            request: \"\"\n            # @param services.docker.deployment.resource.cpu.limit\n            limit: \"\"\n          # @param services.docker.deployment.resource.memory\n          memory:\n            # @param services.docker.deployment.resource.memory.request\n            request: \"\"\n            # @param services.docker.deployment.resource.memory.limit\n            limit: \"\"\n        # @param services.docker.deployment.readiness\n        readiness:\n          # @param services.docker.deployment.readiness.disabled\n          disabled: false\n          # @param services.docker.deployment.readiness.tcpSocketPort\n          tcpSocketPort: 0\n          # @param services.docker.deployment.readiness.httpGet\n          httpGet:\n            # @param services.docker.deployment.readiness.httpGet.path\n            path: \"\"\n            # @param services.docker.deployment.readiness.httpGet.port\n            port: 0\n          # @param services.docker.deployment.readiness.initialDelaySeconds\n          initialDelaySeconds: 0\n          # @param services.docker.deployment.readiness.periodSeconds\n          periodSeconds: 0\n          # @param services.docker.deployment.readiness.timeoutSeconds\n          timeoutSeconds: 0\n          # @param services.docker.deployment.readiness.successThreshold\n          successThreshold: 0\n          # @param services.docker.deployment.readiness.failureThreshold\n          failureThreshold: 0\n        # @param services.docker.deployment.hostnames\n        hostnames:\n          # @param services.docker.deployment.hostnames.host\n          host: \"\"\n          # @param services.docker.deployment.hostnames.acmARN\n          acmARN: \"\"\n          # @param services.docker.deployment.hostnames.defaultInternalHostname\n          defaultInternalHostname: \"\"\n          # @param services.docker.deployment.hostnames.defaultPublicUrl\n          defaultPublicUrl: \"\"\n        # @param services.docker.deployment.network\n        network:\n          # @param services.docker.deployment.network.ipWhitelist\n          ipWhitelist:\n            # @param services.docker.deployment.network.ipWhitelist[]\n            - \"\"\n          # @param services.docker.deployment.network.pathPortMapping\n          pathPortMapping:\n\n          # @param services.docker.deployment.network.hostPortMapping\n          hostPortMapping:\n\n          # @param services.docker.deployment.network.grpc\n          grpc:\n            # @param services.docker.deployment.network.grpc.enable\n            enable: false\n            # @param services.docker.deployment.network.grpc.host\n            host: \"\"\n            # @param services.docker.deployment.network.grpc.defaultHost\n            defaultHost: \"\"\n        # @param services.docker.deployment.serviceDisks\n        serviceDisks:\n          # @param services.docker.deployment.serviceDisks[]\n          - # @param services.docker.deployment.serviceDisks.name (required)\n            name: \"\"\n            # @param services.docker.deployment.serviceDisks.mountPath (required)\n            mountPath: \"\"\n            # @param services.docker.deployment.serviceDisks.accessModes\n            accessModes: \"\"\n            # @param services.docker.deployment.serviceDisks.storageSize (required)\n            storageSize: \"\"\n            # @param services.docker.deployment.serviceDisks.medium\n            medium: \"\"\n```"
  },
  {
    "title": "Terminology",
    "description": null,
    "date": null,
    "path": "docs/getting-started/terminology",
    "body": "This glossary provides an overview of key Lifecycle concepts and terminology. Let's see how they fit into the environment setup and deployment process.\n\n## Repository\n\nA **repository** refers to a GitHub repository. Each environment that is built **must** have a default repository and an associated pull request.\n\n## Service\n\nA **service** is a deployable artifact. It can be a Docker container, CI pipeline, RDS database, or Helm chart. A single repository can contain multiple services.\n\n**Example:** \n`frontend-service` and `frontend-cache` are two services required for the frontend application to function correctly.\n\n## Environment\n\nAn **environment** is a stack of services built and connected together.\n\n- **`defaultServices`** are built and deployed in an environment by default.\n- **`optionalServices`** can be built and deployed only when needed; otherwise, they fallback to the **default static environment**.\n\n## Static Environment\n\nA **static environment** is a long-lived environment based on a pull request. It tracks branches from configured services and updates automatically when new changes are merged.\n\n## Build\n\nA **build** is the actual instance of the process to build and deploy services within an environment.\n\n- Each build is uniquely identified by Lifecycle using a UUID (e.g., `arm-model-060825` or `dev-0`).\n- A build contains **one deploy per service** in the configuration.\n\n## Deploy\n\nA **deploy** manages the build and deployment execution of a service within an environment.\n\n**Example:**\nIn a frontend environment, `frontend-service` and `frontend-cache` are two deploys created for the environment, each mapped to a unique build UUID.\n\n## Webhook\n\nLifecycle can invoke third-party services when a build state changes. Currently, only **Codefresh triggers** are supported.\n\n### Example\n\n- When the build status is `deployed`, trigger end-to-end tests.\n- When the build status is `error`, trigger infrastructure cleanup."
  },
  {
    "title": "Explore static environment",
    "description": "Create the first and default static environment",
    "date": null,
    "path": "docs/getting-started/explore-static-environment",
    "body": "A **static environment** in Lifecycle is a persistent environment that serves as a fallback when dependent services do not need to be rebuilt.\n\nUnlike ephemeral environments that are built on short lived pull requests, static environments are built on top of long lived pull requests. These environments exist continuously and update automatically as changes are merged into the default branch of configured services.\n\n## What is `dev-0`\n\nThe **default static environment** is `dev-0`. This environment ensures that there is always a **stable and up-to-date version** of services available without needing to build every dependency manually.\n\n\n\nThe `dev-0` environment should be created for your installation.\n\nDuring the initial bootstrapping of Lifecycle, the `dev-0` build record is created automatically but this itself does not have any services built.\n\n\n\n## Create `dev-0`\n\n- Delete the dummy `dev-0` build record from `builds` table in the database\n\n```sql\nDELETE FROM builds WHERE uuid = 'dev-0';\n```\n\n- Create a repository named `lifecycle-static-env` in your GitHub account\n- Install the Lifecycle GitHub App in this repository\n- Create a pull request in this repository with branch `dev-0`\n- Add `lifecycle.yaml` file to the root of the repository with all the services you want to include in the `dev-0` environment\n\n  **Example:**\n\n```yaml\nenvironment:\n  defaultServices:\n    - name: \"frontend\"\n      repository: \"account/frontend-repo\"\n      branch: \"main\"\n    - name: \"grpc\"\n      repository: \"account/backend-grpc\"\n      branch: \"main\"\n```\n\n- Deploy the `dev-0` environment by adding `lifecycle-deploy!` label to the pull request\n- Update `uuid` for the environment to `dev-0` in the [mission control comment](/docs/tips/using-mission-control#override-uuid)\n- Finally, execute this query to track default branches of the services in the `dev-0` environment:\n\n```sql\nUPDATE builds\nSET\n    \"trackDefaultBranches\" = true,\n    \"isStatic\" = true\nWHERE\n    uuid = 'dev-0';\n```\n\n## Key Features\n\n**üèóÔ∏è Fallback for Optional Services**\n\n- When optional services are not explicitly built in an ephemeral environment, Lifecycle defaults to using the latest build from `dev-0`.\n\n**üí™ Based on a Persistent PR**\n\n- Similar to ephemeral environments, `dev-0` is based on a PR, but it remains open and continuously updates.\n\n**üë£ Tracks Changes on Default Branch Merges**\n\n- Whenever a service has a new change merged to its `main` branch, `dev-0` will **automatically pull, build, and redeploy** the latest changes.\n- This ensures `dev-0` always contains **the freshest version** of all services."
  },
  {
    "title": "Configure environment",
    "description": null,
    "date": null,
    "path": "docs/getting-started/configure-environment",
    "body": "Now that we've created and deployed our first Lifecycle environment, let's learn how to customize it by configuring services and dependencies.\n\n## Understanding Configuration\n\nFirst, let's take a look at the `lifecycle.yaml` configuration file at the root dir of [lifecycle-examples](https://github.com/GoodRxOSS/lifecycle-examples/blob/main/lifecycle.yaml) repository:\n\n```yaml filename=\"lifecycle.yaml\"\nenvironment:\n  autoDeploy: true\n  defaultServices:\n    - name: \"frontend\"\n    - name: \"backend\"\n  optionalServices:\n    - name: \"cache\"\n\nservices:\n  - name: \"frontend\"\n    defaultUUID: \"dev-0\"\n    github:\n      repository: \"iceycake/lifecycle-examples\"\n      branchName: \"main\"\n      docker:\n        builder:\n          engine: \"buildkit\"\n        defaultTag: \"main\"\n        app:\n          dockerfilePath: \"Dockerfile.frontend\"\n          ports:\n            - 3000\n          env:\n            COMPONENT: \"app\"\n            ENV: \"lifecycle\"\n            API_URL: \"https://{{{backend_publicUrl}}}\"\n            CACHE_URL: \"{{{cache_internalHostname}}}\"\n            WES_IS: \"GOAT\"\n  - name: \"backend\"\n    requires:\n      - name: \"db\"\n    defaultUUID: \"dev-0\"\n    # ...\n  - name: \"db\"\n    defaultUUID: \"dev-0\"\n    # ...\n  - name: \"cache\"\n    defaultUUID: \"dev-0\"\n    # ...\n```\n\n### Default and Optional Services\n\nWe have our dependencies defined in **`defaultServices`** and **`optionalServices`**:\n\n- **`defaultServices`** ‚Äì These services are always **built and deployed** with the environment. They form the core foundation of the environment and are required for it to function correctly.\n- **`optionalServices`** ‚Äì These services **can be built on demand**, only when explicitly needed. If they are not selected during a PR, they default to using a **static environment** (e.g., `dev-0`).\n\n### Template Variables\n\nNotice how there are template variables defined in service named `frontend` > `github.docker.env`:\n\n```yaml\nAPI_URL: \"https://{{{backend_publicUrl}}}\"\nCACHE_URL: \"{{{cache_internalHostname}}}\"\n```\n\nThis `API_URL` and `CACHE_URL` variables are dynamically templated by Lifecycle and provided during the **build** and **deploy** steps for the frontend service.\n\n\n  Read more about supported template variables\n  [here](/docs/features/template-variables)\n\n\n## Static Environment as a Fallback\n\nSince `cache` is an **optional service**, this service defaulted to using a **static environment**(`dev-0`) as a fallback. This allows us to reuse existing environments instead of rebuilding everything from scratch when there are no changes.\n\n### Check Template Variables\n\nTo view how the fallback URL works,\n\n1. Open your **Tasks App**(frontend) from the deployed environment.\n2. Navigate to the `Variables` page.\n3. Search for `_URL` and check its value.\n   - It should look like:\n     ```\n     API_URL: https://backend-.\n     CACHE_URL: cache-dev-0.env-dev-0.svc.cluster.local\n     ```\n   - Notice how `CACHE_URL` defaults to the `dev-0`(static) environment for the optional cache.\n\n## Configuring Services\n\nNow, let's say you also want to the `cache` component to **test, build and deploy it in your environment**.\n\n### Enable Cache Deployment\n\n1. Navigate to the **Lifecycle PR comment** on GitHub.\n2. Select the `cache` checkbox in the comment. That's it!\n3. Lifecycle will now start **building and deploying the cache service** for your specific environment.\n4. Wait for the build to complete. You can monitor the progress in the **status comment**.\n\n### Confirm the New Cache URL\n\n5. Once the cache is deployed, go back to your **frontend app‚Äôs Variables page**.\n6. Check the `CACHE_URL` value.\n   - It should now look like:\n     ```\n     cache-.env-.svc.cluster.local\n     ```\n7. Now, you're running your cache **from your own environment** instead of an existing static deploy!\n8. Check the application‚Äôs **Tasks** page while you‚Äôre here and observe the completely different data, as this environment uses a freshly built and seeded database.\n\n## Build Flexible Environments\n\nWith this approach, you can:\n\n- Build **any combination** of frontend and backend services.\n- Use **custom branches** for different services.\n- Test **different versions** of your app.\n\n\n  Check how to use Mission Control comments for configuring your environment\n  [here](/docs/tips/using-mission-control)\n\n\nThis gives you a **custom, isolated testing environment** that mirrors your\nproduction setup while allowing flexibility in development and validation.\n\n## Summary\n\n- Services marked as **optional** in `lifecycle.yaml` will default to static environments unless explicitly built.\n- You can enable/disable any service directly from the **Lifecycle PR comment**.\n- Lifecycle automates dependency management, ensuring your services deploy in the correct order.\n\n**Now you're ready to customize your Lifecycle environments like a pro!** üë©‚Äçüíª"
  },
  {
    "title": "Explore environment",
    "description": null,
    "date": null,
    "path": "docs/getting-started/explore-environment",
    "body": "Now that we've deployed our first Lifecycle environment, let‚Äôs take a tour of the PR comments to understand how to interact with our ephemeral environment.\n\n## Test Your Application\n\nLet's navigate to the deployed `frontend` app from the PR comment.\n\n1. Click on the `frontend` link in the PR comment to navigate to your deployed application.\n2. Add a task and complete few tasks to update data in backend.\n3. Navigate to the `variables` page and checkout the variables in your application's container.\n4. Thats it! You have successfully deployed and tested the best todo app in the world! üéâ\n\n## Mission Control Comment\n\nThe **Lifecycle PR comment** in your pull request serves as the **mission control** for your ephemeral environment.\n\n\n\n### What You Can Do in the PR Comment\n\n- **Editable Checkboxes**: Select or deselect services to include in your environment.\n- **Redeploy Checkbox**: Triggers a redeploy (useful for transient issues).\n- **Deployment Section**: Provides URLs to your **deployed services**.\n\n}>\n  Read more about [Mission Control comment\n  here](/docs/tips/using-mission-control.mdx)\n\n\n## Status Comment\n\nWhen we add the `lifecycle-status-comments!` label to our pull request, Lifecycle will automatically add a **status comment** to the PR.\n\nThis comment provides real-time updates on the status, links to your deployments including the build progress and service statuses.\n\n\n\nNotice the following while the environment is being built:\n\n- The status comment is **updated in real-time**.\n- The **status** of each service is displayed.\n- The **build logs** are available for each service.\n\n\n\n### Next Steps\n\nIn the next section, we will:\n\n‚öôÔ∏è Customize our configuration\n‚òëÔ∏è Enable and build an optional service(`cache`) support your application\n\n**Ready to level up your ephemeral environment? Let\\'s go!** üèÉ‚Äç‚û°Ô∏è"
  },
  {
    "title": "Create environment",
    "description": null,
    "date": null,
    "path": "docs/getting-started/create-environment",
    "body": "In this walk through, we will make a simple change to an example frontend repository and create our first ephemeral environment using Lifecycle.\n\n## 1. Fork the Repository\n\nFork the [`lifecycle-examples`](https://github.com/GoodRxOSS/lifecycle-examples) repository to your org or personal account and install your newly minted GitHub App to the forked repository.\n\n- Navigate to `https://github.com/settings/apps` (for personal accounts) or `https://github.com/organizations//settings/apps` (for org accounts).\n- Find the **Lifecycle GitHub App** and click on **Edit**.\n- Choose `Install App` from sidebar and click the Settings  icon.\n- Select the forked repository from the list and select **Save**.\n\n## 2. Create a New Branch\n\nClone the repo and create a branch named `lfc-config`:\n\n```sh\ngit checkout -b lfc-config\n```\n\nor if you are using GitHub Desktop, you can create a new branch from the UI.\n\n## 3. Update Lifecycle Configuration\n\nOpen the `lifecycle.yaml` file in the root of the repository and update the `frontend` service's repository to your github username or org.\n\n**Before:**\n\n```yaml filename=\"lifecycle.yaml\"\ngithub:\n  repository: \"GoodRxOSS/lifecycle-examples\"\n```\n\n**After:**\n\n```yaml filename=\"lifecycle.yaml\"\ngithub:\n  repository: \"/lifecycle-examples\"\n```\n\n## 4. Commit & Push Your Changes\n\n```sh\ngit add .\ngit commit -m \"update config\"\ngit push origin lfc-config\n```\n\n## 5. Create a Pull Request\n\n1. Open a **Pull Request (PR)** from `lfc-config` to `main` in the forked repository.\n2. Submit the PR.\n\n## 6. Lifecycle PR Comment\n\nAfter submitting the PR, you‚Äôll see a **GitHub comment from Lifecycle** on your pull request.\n\nüîπ This PR comment is the **mission control** for your ephemeral environment. It provides:\n\n- A **status update** of the build and deploy process.\n- A **list of services** configured for the environment.\n- A **link to the Lifecycle UI** where you can view logs, deployments, and environment details.\n\n\n  If there is no comment from Lifecycle, it means the app is not configured\n  correctly or the GitHub App is not installed in the repository. Please refer\n  to the [Missing Comment](/docs/troubleshooting/github-app-webhooks) page for\n  more information.\n\n\n## 7. Add `lifecycle-status-comments!` label\n\nThe additional label `lifecycle-status-comments!` provides more detailed information about the environment status and links to access the running application.\n\nüîπ The comments provides insights into:\n\n- **Build & Deploy Status**: Track when your environment is ready.\n- **Environment URLs**: Access the running frontend app.\n- **Telemetry Links**: Links to telemetry, build and deploy logs. (if enabled)\n\n## 8. Wait for Deployment\n\nWait for the **builds & deploys** to complete. Once the status updates to **`deployed`**, your environment is live! üöÄ\n\nWhen a new commit is pushed to your pull request Lifecycle automatically builds and deploys again so you always have the latest version of the application.\n\n\n  If there are any errors during the build or deploy process, the environment\n  will not be created, and you will see an error message in the Lifecycle\n  comment.\n  \n  \n    You can check the logs from `lifecycle-worker` pods in your cluster to debug\n    the issue:  `kubectl logs deploy/lifecycle-worker -n lifecycle-app -f\n    `\n  \n\n\n## 9. Checkout the deployed application\n\nOnce the deployment is complete, you can access your environment at the URL provided in the Lifecycle comment on your pull request. Click on the `frontend` link to open your application in a new tab.\n\nThe application has two simple pages:\n\n- **`/tasks`** ‚Äì A simple to-do list.\n- **`/variables`** ‚Äì Displays all environment variables from the container.\n\n## Next Steps\n\nNow that your first ephemeral environment is ready, move on to the next section where we:\n\nüß™ Test the environment.\nüß≠ Explore the comments and logs.\n‚öôÔ∏è Customize the configuration."
  },
  {
    "title": "Delete environment",
    "description": null,
    "date": null,
    "path": "docs/getting-started/delete-environment",
    "body": "To **tear down** an environment, you can do one of the following:\n\n1. **Merge or close the pull request**: This will automatically clean up the environment.\n2. **Apply the `lifecycle-disabled!` label**: This will immediately trigger the environment deletion process.\n\n---\n\nThe **`lifecycle-disabled!`** label is useful in scenarios where:\n\n- The environment infrastructure is **experiencing issues**.\n- The data within the environment is **corrupt**.\n- You need to **restart or rebuild** the environment from scratch without waiting for a PR to be merged or closed.\n\nSimply apply the label to the **PR associated with the environment**, and Lifecycle will automatically tear it down.\n\n\n  Read more about how pull request labels control auto deploy in repositories\n  [here](/docs/features/auto-deployment)\n\n\n---\n\nUsing these methods, you can efficiently manage and clean up environments to ensure smooth development and testing workflows. üßπ"
  },
  {
    "title": "Telemetry",
    "description": null,
    "date": null,
    "path": "docs/tips/telemetry",
    "body": "Lifecycle comes with built-in support for Datadog telemetry. To collect logs and metrics from your cluster and deployed applications, install the Datadog Agent and Cluster Agent in your cluster.\n\nThe deployed applications are already configured with the necessary Datadog labels and environment variables for seamless integration:\n\n**Pod labels:**\n\n```yaml\ntags.datadoghq.com/env: lifecycle-binlab-zero-101010\ntags.datadoghq.com/service: frontend\ntags.datadoghq.com/version: binlab-zero-101010\n```\n\n**Environment variables:**\n\n```yaml\n- name: DD_ENV\n  valueFrom:\n    fieldRef:\n      apiVersion: v1\n      fieldPath: metadata.labels['tags.datadoghq.com/env']\n- name: DD_SERVICE\n  valueFrom:\n    fieldRef:\n      apiVersion: v1\n      fieldPath: metadata.labels['tags.datadoghq.com/service']\n- name: DD_VERSION\n  valueFrom:\n    fieldRef:\n      apiVersion: v1\n      fieldPath: metadata.labels['tags.datadoghq.com/version']\n```\n\nThis setup ensures that Datadog automatically detects the environment, service, and version for each application, enabling rich observability and correlation of logs and metrics in the Datadog platform."
  },
  {
    "title": "Mission Control comment",
    "description": "Use the Mission Control PR Comment to modify and customize your environment directly from the pull request comment.",
    "date": null,
    "path": "docs/tips/using-mission-control",
    "body": "Lifecycle uses **Mission Control PR Comments** to allow users to modify and customize their environments directly from the pull request comment. This enables easy **service selection**, **branch customization**, and **environment variable overrides** without modifying `lifecycle.yaml`.\n\n---\n\n## Selecting and Deselecting Services\n\nEach pull request environment includes **default services** and optional additional services. You can enable or disable services using the checkboxes.\n\n- **Enabled Services** are marked with `[x]`.\n- **Disabled Services** are marked with `[ ]`.\n\n**Example:**\n\n```md\n// Default Services\n\n- [x] frontend: dev-default\n- [x] fastly: main\n\n// Optional Additional Services\n\n- [ ] backend-service: main\n- [ ] backend-db: main\n- [ ] backend-cache: main\n```\n\nTo **enable** a service, change `[ ]` to `[x]`. To **disable** a service, change `[x]` to `[ ]`. As simple as that!\n\n\n  If you need to make multiple selections or deselections at once, use the\n  **Edit Comment** option instead of clicking checkboxes individually. This\n  prevents multiple back-to-back builds, as each selection triggers an event in\n  Lifecycle without deduplication.\n\n\n## Choosing a Branch\n\nTo deploy a specific branch for a service, modify the branch name after the service name.\n\n**Example:**\n\n```md\n- [x] frontend: feature-branch\n- [x] fastly: main\n```\n\nThis will deploy `frontend` using the `feature-branch` instead of the default branch.\n\n## Overriding Environment Variables\n\nTo set additional environment variables, use the **Override Environment Variables** section in the PR comment.\n\n**Example:**\n\n```md\n// **Override Environment Variables:** _ENV:[KEY]:[VALUE]_\nENV:API_URL:https://api.custom.dev.0env.com\nENV:CHIEF_INTERN:ICEYCAKE\n```\n\nThis sets `API_URL` and `CHIEF_INTERN` in the environment without modifying the service configuration.\n\n## Override UUID\n\nTo set a custom UUID (subdomain) for the environment, use the **Override UUID** section in the PR comment.\n\n```md\n// UUID (Pick your own custom subdomain)\nurl: wagon-builder-060825\n```\n\nReplace `wagon-builder-060825` with your desired subdomain. This allows you to customize the environment URL without changing the underlying service configuration.\n\n---\n\nUsing the **Mission Control PR Comment**, you can easily customize your environment **without modifying code**, making it a flexible way to test and deploy changes dynamically."
  }
]